\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Steps of the process}}{2}{figure.caption.7}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Comparison of classification (left) with output: 'Cat' and object detection (right) with output: 'Cat, Dog' and their localization with bounding boxes }}{7}{figure.caption.8}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Landmarks for pose estimation model by MediaPipe and U-Net segmentation on an image from Oxford-IIIT Pet Dataset (Parkhi et al, 2012).}}{8}{figure.caption.9}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Schematic representation of a neuron with inputs, weights, a bias, an activation function, and an output.}}{8}{figure.caption.10}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Structure of neural network}}{9}{figure.caption.11}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces A diagram of the NN softmax classification process.}}{11}{figure.caption.12}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Softmax/Sigmoid function and Rectifier function.}}{11}{figure.caption.13}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces An example structure for backpropagation.}}{15}{figure.caption.16}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Visualization of dropout.}}{18}{figure.caption.17}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Cyberglove II}}{20}{figure.caption.18}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Hand landmarks model output.}}{23}{figure.caption.19}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Process of normalization of landmark coordinates.}}{24}{figure.caption.20}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Outputs of face detection model with different lightings}}{25}{figure.caption.21}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Hand gestures using the MediaPipe Landmark Model, using the following gestures: Palm, Fist, Rock, Ok, Like, Up, Down, and Peace.}}{26}{figure.caption.22}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Fully connected neural network architecture with three hidden layers.}}{28}{figure.caption.24}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Confusion matrix displaying the performance of the classification model across 8 classes. The x-axis represents the predicted class labels, while the y-axis shows the true class labels. The diagonal cells, highlighted in darker shades, indicate the number of correct predictions for each class, with the off-diagonal cells showing the instances of misclassifications.}}{30}{figure.caption.26}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Training and validation loss curves for a neural network model utilizing the ReLU activation function.}}{31}{figure.caption.27}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Comparative analysis of different optimizers.}}{32}{figure.caption.28}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Training and validation accuracy over epochs for different initial learning rates using the Adam optimizer.}}{32}{figure.caption.29}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces The effect of batch size on model loss during training and validation.}}{33}{figure.caption.30}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Model loss using the ReLU activation function plotted over 1000 epochs without early stopping.}}{35}{figure.caption.32}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Logic in the recognition process.}}{36}{figure.caption.33}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces Drone used in this project.}}{37}{figure.caption.34}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Gesture recognition shots from the drone camera right before command execution.}}{38}{figure.caption.36}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Outputs of FaceBlaze and Face Landmark model.}}{39}{figure.caption.37}%
\addvspace {10\p@ }
\addvspace {10\p@ }
