\chapter{Conclusions}
In this thesis we designed and developed
 a reliable system that classifies hand gestures for controlling a drone through
 its embedded camera system.
  This was achieved by~integrating machine learning models for real-time image processing. MediaPipe, an open-source framework, was utilized for hand tracking, while TensorFlow, an open-source machine learning framework, was used for developing the model. 
  For efficient gesture classification, we utilized a neural network.
  
   The model was designed to handle diverse hand orientations and lighting conditions encountered during drone operation. 
 The model achieved success by extracting features from 21 landmarks on each hand, rather than relying solely on images processed with classical methods. 

To evaluate the efficiency of the prediction model, it was empirically tested, and an accuracy of 99.62\% was achieved on the testing set. The model's ability to generalize well to new, unseen data was a critical requirement for real-world applications, and this was achieved through a classification report that yielded high precision, recall, and F1 scores across all classes. The model's architecture is based on deep learning research and employs dropout layers and dense networks with ReLU activations.

The model successfully demonstrated its ability to accurately distinguish between nuanced hand gestures, providing reliable navigation commands to the drone. The minimal number of misclassifications is a testament to the model's precision in differentiating between the hand gestures.
In this study, it was demonstrated that the implementation of the model using TensorFlow Lite resulted in an efficient translation of computational power and performance in the context of a hardware-focused system such as the Tello drone. This successful implementation highlights the practicality of incorporating advanced machine-learning algorithms in environments with limited resources. 
In conclusion, we designed, developed, and implemented a machine learning system that provides accurate, efficient, and reliable gesture-based control of a drone.
 Through extensive testing, the practical applications of this system were validated, and its adaptability across a range of gestures was proved. This achievement lays the groundwork for future advancements in touchless drone control interfaces, or work~with authentication, and opens new doors for exploration in the field of human-computer interaction.
