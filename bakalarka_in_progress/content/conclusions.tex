\chapter{Conclusions}
The aim of this thesis was to design and develop a reliable system that classifies hand gestures for controlling a drone through an embedded camera system. This was achieved by integrating machine learning models for real-time image processing. MediaPipe, an open-source framework, was utilized for hand tracking, while TensorFlow, an open-source machine learning framework, was used for developing the model. To classify gestures efficiently, a neural network was designed based on deep learning research. The model was designed to handle diverse hand orientations and lighting conditions encountered during drone operation. The backbone of this achievement was the fact, that the model wasn't trained on just images processed with classical methods, but rather extracted features were represent 21 landmarks on each hand.

To evaluate the efficiency of the prediction model, it was empirically tested, and an accuracy of 99.62\% was achieved on the testing set. The model's ability to generalize well to new, unseen data was a critical requirement for real-world applications, and this was achieved through a meticulously designed classification report that yielded high precision, recall, and F1-scores across all classes. The model's architecture is based on deep learning research and employs dropout layers and dense networks with ReLU activations.

The model's ability to differentiate between nuanced hand positions effectively was demonstrated, ensuring reliable drone navigation commands. The minimal number of misclassifications is indicative of the model's capacity to differentiate between nuanced hand positions effectively. A quantitative analysis using a confusion matrix was done to discern the model's ability to differentiate between similar gestures with a high degree of accuracy.

The model was implemented in TensorFlow Lite, which showcased an effective translation of computational efficiency and performance into an embedded system context, such as the Tello drone used in this study. This implementation demonstrates the practical feasibility of applying advanced machine learning algorithms in resource-constrained environments, which is a key consideration in the development of autonomous systems.

In conclusion, the thesis aimed to design, develop, and implement a machine learning system that provides accurate, efficient, and reliable gesture-based control of a drone. Through extensive testing, the practical applications of this system were validated, and its adaptability across a range of gestures and operational scenarios was confirmed. This achievement lays the groundwork for future advancements in touchless drone control interfaces and opens new avenues for exploration in the field of human-computer interaction.
\clearpage