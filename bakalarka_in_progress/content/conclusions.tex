\chapter{Conclusions}
This thesis aimed to design and develop a reliable system that classifies hand gestures for controlling a drone through an embedded camera system. This was achieved by integrating machine learning models for real-time image processing. MediaPipe, an open-source framework, was utilized for hand tracking, while TensorFlow, an open-source machine learning framework, was used for developing the model. To classify gestures efficiently, a neural network was designed based on deep learning research. The model was designed to handle diverse hand orientations and lighting conditions encountered during drone operation. The backbone of this achievement was the fact, that the model wasn't trained on just images processed with classical methods, but rather extracted features represented 21 landmarks on each hand.

To evaluate the efficiency of the prediction model, it was empirically tested, and an accuracy of 99.62\% was achieved on the testing set. The model's ability to generalize well to new, unseen data was a critical requirement for real-world applications, and this was achieved through a classification report that yielded high precision, recall, and F1 scores across all classes. The model's architecture is based on deep learning research and employs dropout layers and dense networks with ReLU activations.

The model successfully demonstrated its ability to accurately distinguish between nuanced hand gestures, providing reliable navigation commands to the drone. The minimal number of misclassifications is a testament to the model's precision in differentiating between the hand gestures.
In this study, it was demonstrated that the implementation of the model using TensorFlow Lite resulted in an efficient translation of computational power and performance in the context of an embedded system, like the Tello drone. This successful implementation highlights the practicality of incorporating advanced machine-learning algorithms in environments with limited resources. 

In conclusion, the thesis aims to design, develop, and implement a machine learning system that provides accurate, efficient, and reliable gesture-based control of a drone. Through extensive testing, the practical applications of this system were validated, and its adaptability across a range of gestures was proved. This achievement lays the groundwork for future advancements in touchless drone control interfaces, or work with authentication, and opens new doors for exploration in the field of human-computer interaction.
